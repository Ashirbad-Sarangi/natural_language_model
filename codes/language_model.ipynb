{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed71b52b-3ff8-4532-ae3a-64bf1950ebe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 18:04:00.228017: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-13 18:04:00.230138: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-13 18:04:00.297566: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-13 18:04:00.578171: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 18:04:01.432698: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as analytics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23721dfb-332a-4eea-8c7b-3ef84bef43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = analytics.read_csv('../data/ptb.train.txt', header = None)\n",
    "corpus = []\n",
    "for i in range(len(df_corpus[:5000])):\n",
    "    text = df_corpus.iloc[i][0].strip()\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baaaf74d-0799-49a9-a4ff-867e2a7aef3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashirbad/.local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2024-04-13 18:04:03.834480: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 42ms/step - accuracy: 0.0748 - loss: 6.7744\n",
      "Epoch 2/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 42ms/step - accuracy: 0.1408 - loss: 5.8113\n",
      "Epoch 3/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 43ms/step - accuracy: 0.1728 - loss: 5.3263\n",
      "Epoch 4/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 43ms/step - accuracy: 0.1954 - loss: 4.9337\n",
      "Epoch 5/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 43ms/step - accuracy: 0.2190 - loss: 4.5563\n",
      "Epoch 6/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 43ms/step - accuracy: 0.2396 - loss: 4.2273\n",
      "Epoch 7/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 43ms/step - accuracy: 0.2698 - loss: 3.8843\n",
      "Epoch 8/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 43ms/step - accuracy: 0.3009 - loss: 3.6049\n",
      "Epoch 9/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 43ms/step - accuracy: 0.3377 - loss: 3.3181\n",
      "Epoch 10/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 43ms/step - accuracy: 0.3785 - loss: 3.0556\n",
      "Epoch 11/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 43ms/step - accuracy: 0.4157 - loss: 2.8299\n",
      "Epoch 12/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 43ms/step - accuracy: 0.4555 - loss: 2.6048\n",
      "Epoch 13/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 43ms/step - accuracy: 0.4930 - loss: 2.4135\n",
      "Epoch 14/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 43ms/step - accuracy: 0.5271 - loss: 2.2406\n",
      "Epoch 15/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 43ms/step - accuracy: 0.5545 - loss: 2.0860\n",
      "Epoch 16/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 43ms/step - accuracy: 0.5883 - loss: 1.9345\n",
      "Epoch 17/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 43ms/step - accuracy: 0.6171 - loss: 1.8042\n",
      "Epoch 18/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 45ms/step - accuracy: 0.6387 - loss: 1.6891\n",
      "Epoch 19/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 45ms/step - accuracy: 0.6593 - loss: 1.5819\n",
      "Epoch 20/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 45ms/step - accuracy: 0.6851 - loss: 1.4689\n",
      "Epoch 21/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 46ms/step - accuracy: 0.7043 - loss: 1.3777\n",
      "Epoch 22/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 49ms/step - accuracy: 0.7217 - loss: 1.2988\n",
      "Epoch 23/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 45ms/step - accuracy: 0.7390 - loss: 1.2167\n",
      "Epoch 24/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 48ms/step - accuracy: 0.7528 - loss: 1.1524\n",
      "Epoch 25/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 44ms/step - accuracy: 0.7665 - loss: 1.0902\n",
      "Epoch 26/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 45ms/step - accuracy: 0.7823 - loss: 1.0202\n",
      "Epoch 27/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 45ms/step - accuracy: 0.7923 - loss: 0.9771\n",
      "Epoch 28/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 45ms/step - accuracy: 0.8023 - loss: 0.9283\n",
      "Epoch 29/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 49ms/step - accuracy: 0.8128 - loss: 0.8799\n",
      "Epoch 30/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 46ms/step - accuracy: 0.8233 - loss: 0.8373\n",
      "Epoch 31/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 45ms/step - accuracy: 0.8311 - loss: 0.7998\n",
      "Epoch 32/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 46ms/step - accuracy: 0.8374 - loss: 0.7694\n",
      "Epoch 33/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 45ms/step - accuracy: 0.8455 - loss: 0.7289\n",
      "Epoch 34/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 46ms/step - accuracy: 0.8452 - loss: 0.7192\n",
      "Epoch 35/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 46ms/step - accuracy: 0.8532 - loss: 0.6886\n",
      "Epoch 36/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 46ms/step - accuracy: 0.8585 - loss: 0.6629\n",
      "Epoch 37/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 46ms/step - accuracy: 0.8662 - loss: 0.6338\n",
      "Epoch 38/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 45ms/step - accuracy: 0.8690 - loss: 0.6173\n",
      "Epoch 39/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 48ms/step - accuracy: 0.8743 - loss: 0.5966\n",
      "Epoch 40/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 51ms/step - accuracy: 0.8764 - loss: 0.5796\n",
      "Epoch 41/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 51ms/step - accuracy: 0.8812 - loss: 0.5617\n",
      "Epoch 42/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 51ms/step - accuracy: 0.8852 - loss: 0.5359\n",
      "Epoch 43/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 51ms/step - accuracy: 0.8892 - loss: 0.5215\n",
      "Epoch 44/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 48ms/step - accuracy: 0.8918 - loss: 0.5098\n",
      "Epoch 45/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 45ms/step - accuracy: 0.8940 - loss: 0.5006\n",
      "Epoch 46/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 44ms/step - accuracy: 0.8941 - loss: 0.4923\n",
      "Epoch 47/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 44ms/step - accuracy: 0.8981 - loss: 0.4743\n",
      "Epoch 48/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 44ms/step - accuracy: 0.8984 - loss: 0.4717\n",
      "Epoch 49/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 44ms/step - accuracy: 0.9003 - loss: 0.4612\n",
      "Epoch 50/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 45ms/step - accuracy: 0.9031 - loss: 0.4488\n",
      "Epoch 51/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 45ms/step - accuracy: 0.9044 - loss: 0.4381\n",
      "Epoch 52/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 44ms/step - accuracy: 0.9051 - loss: 0.4368\n",
      "Epoch 53/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 45ms/step - accuracy: 0.9097 - loss: 0.4190\n",
      "Epoch 54/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 45ms/step - accuracy: 0.9069 - loss: 0.4262\n",
      "Epoch 55/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 45ms/step - accuracy: 0.9081 - loss: 0.4146\n",
      "Epoch 56/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 45ms/step - accuracy: 0.9080 - loss: 0.4124\n",
      "Epoch 57/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 45ms/step - accuracy: 0.9111 - loss: 0.4024\n",
      "Epoch 58/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4058\n",
      "Epoch 59/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 45ms/step - accuracy: 0.9106 - loss: 0.4043\n",
      "Epoch 60/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 45ms/step - accuracy: 0.9108 - loss: 0.3992\n",
      "Epoch 61/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 45ms/step - accuracy: 0.9136 - loss: 0.3895\n",
      "Epoch 62/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 45ms/step - accuracy: 0.9133 - loss: 0.3827\n",
      "Epoch 63/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 45ms/step - accuracy: 0.9137 - loss: 0.3810\n",
      "Epoch 64/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 45ms/step - accuracy: 0.9121 - loss: 0.3867\n",
      "Epoch 65/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 45ms/step - accuracy: 0.9148 - loss: 0.3743\n",
      "Epoch 66/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 45ms/step - accuracy: 0.9139 - loss: 0.3810\n",
      "Epoch 67/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 45ms/step - accuracy: 0.9142 - loss: 0.3800\n",
      "Epoch 68/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 45ms/step - accuracy: 0.9040 - loss: 0.4086\n",
      "Epoch 69/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 45ms/step - accuracy: 0.9166 - loss: 0.3645\n",
      "Epoch 70/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 45ms/step - accuracy: 0.9134 - loss: 0.3759\n",
      "Epoch 71/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 45ms/step - accuracy: 0.9147 - loss: 0.3661\n",
      "Epoch 72/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 45ms/step - accuracy: 0.9134 - loss: 0.3723\n",
      "Epoch 73/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 45ms/step - accuracy: 0.9155 - loss: 0.3635\n",
      "Epoch 74/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 45ms/step - accuracy: 0.9149 - loss: 0.3646\n",
      "Epoch 75/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 45ms/step - accuracy: 0.9176 - loss: 0.3567\n",
      "Epoch 76/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 46ms/step - accuracy: 0.9197 - loss: 0.3523\n",
      "Epoch 77/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 45ms/step - accuracy: 0.9163 - loss: 0.3566\n",
      "Epoch 78/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 48ms/step - accuracy: 0.9172 - loss: 0.3565\n",
      "Epoch 79/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 53ms/step - accuracy: 0.9177 - loss: 0.3522\n",
      "Epoch 80/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 53ms/step - accuracy: 0.9173 - loss: 0.3519\n",
      "Epoch 81/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 53ms/step - accuracy: 0.9180 - loss: 0.3494\n",
      "Epoch 82/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 53ms/step - accuracy: 0.9167 - loss: 0.3493\n",
      "Epoch 83/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 53ms/step - accuracy: 0.9164 - loss: 0.3511\n",
      "Epoch 84/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 53ms/step - accuracy: 0.9168 - loss: 0.3516\n",
      "Epoch 85/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 48ms/step - accuracy: 0.9190 - loss: 0.3414\n",
      "Epoch 86/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 52ms/step - accuracy: 0.9182 - loss: 0.3442\n",
      "Epoch 87/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 53ms/step - accuracy: 0.9183 - loss: 0.3409\n",
      "Epoch 88/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 53ms/step - accuracy: 0.9199 - loss: 0.3394\n",
      "Epoch 89/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 53ms/step - accuracy: 0.9182 - loss: 0.3418\n",
      "Epoch 90/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 54ms/step - accuracy: 0.9176 - loss: 0.3441\n",
      "Epoch 91/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 54ms/step - accuracy: 0.9168 - loss: 0.3469\n",
      "Epoch 92/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 54ms/step - accuracy: 0.9189 - loss: 0.3378\n",
      "Epoch 93/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 49ms/step - accuracy: 0.9153 - loss: 0.3477\n",
      "Epoch 94/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 51ms/step - accuracy: 0.9199 - loss: 0.3368\n",
      "Epoch 95/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 46ms/step - accuracy: 0.9173 - loss: 0.3424\n",
      "Epoch 96/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 52ms/step - accuracy: 0.9189 - loss: 0.3347\n",
      "Epoch 97/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 54ms/step - accuracy: 0.9182 - loss: 0.3382\n",
      "Epoch 98/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 53ms/step - accuracy: 0.9182 - loss: 0.3401\n",
      "Epoch 99/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 54ms/step - accuracy: 0.9201 - loss: 0.3317\n",
      "Epoch 100/100\n",
      "\u001b[1m3161/3161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 54ms/step - accuracy: 0.9177 - loss: 0.3371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7bb0c417cd00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example corpus\n",
    "# corpus = [\n",
    "#     \"This is a simple example sentence.\",\n",
    "#     \"Another example sentence for training.\"\n",
    "# ]\n",
    "\n",
    "# Tokenize the corpus\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Generate input sequences\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Create predictors and labels\n",
    "X, y = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0bb4b39-fdf2-44b2-b131-2655c8214759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_model.keras/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_model.keras/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model,\"trained_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a31de0-e1e0-40fc-872e-27ccd7742220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">697,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6977</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,053,527</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m697,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6977\u001b[0m)           │     \u001b[38;5;34m1,053,527\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,705,483</span> (21.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,705,483\u001b[0m (21.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,901,827</span> (7.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,901,827\u001b[0m (7.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,803,656</span> (14.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3,803,656\u001b[0m (14.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81754159-0008-483a-8a46-b3fbf98a9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('trained_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e303a7c-35ea-4d34-86d1-f9ffa345410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate text\n",
    "def generate_text(seed_text, next_words, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        # Tokenize the seed text\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        # Pad the token list\n",
    "        token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        # Predict the next word\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "        # Sample the next word based on the predicted probabilities\n",
    "        predicted_word_index = np.random.choice(len(predicted_probs), p=predicted_probs)\n",
    "        # Convert the predicted word index back to the actual word\n",
    "        predicted_word = tokenizer.index_word.get(predicted_word_index, \"\")\n",
    "        # Update the seed text with the predicted word\n",
    "        seed_text += \" \" + predicted_word\n",
    "    return seed_text\n",
    "\n",
    "# Example usage\n",
    "# seed_text = \"nonexecutive director\"\n",
    "# generated_text = generate_text(seed_text, next_words=10, max_sequence_len=max_sequence_len)\n",
    "# print(\"Generated Text:\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b39c22-8db9-4331-bb0b-66a657337590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the chatbot !\n",
      "\n",
      " Welcome the unk construction practices and unk workout of the company\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your response :  yellow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " yellow first financial corp said its unk ships are n't expected\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your response :  color\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " color company said it was a registration to increase n and\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stop_word = \"Thank You !\"\n",
    "input_text = \"Welcome\"\n",
    "print(\"Welcome to the chatbot !\")\n",
    "while input_text != stop_word :\n",
    "    print(\"\\n\",generate_text(input_text, next_words=10, max_sequence_len=max_sequence_len))\n",
    "    print(\"\\n\")\n",
    "    input_text = input(\"Enter your response : \")\n",
    "\n",
    "print(\"\\n\\n\\nIt was great talking with you !!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
