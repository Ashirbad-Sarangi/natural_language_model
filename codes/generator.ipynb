{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a0bf79-27c1-4191-a4dd-670de1b95924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 00:11:57.056722: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-17 00:11:57.878066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as analytics\n",
    "import numpy as maths\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from locations import treebank_training_path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c926b8a-9b17-4d35-997b-7a9ec4ce672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = analytics.read_csv(treebank_training_path)\n",
    "corpus = []\n",
    "for i in range(len(df_train)):\n",
    "    text = df_train.iloc[i]['data']\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092862c2-7f1f-4c08-9d4b-422b1487676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to generate text\n",
    "# def generate_text(seed_text, next_words, max_sequence_len):\n",
    "#     for _ in range(next_words):\n",
    "#         # Tokenize the seed text\n",
    "#         token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "#         # Pad the token list\n",
    "#         token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "#         # Predict the next word\n",
    "#         predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "#         # Sample the next word based on the predicted probabilities\n",
    "#         predicted_word_index = maths.random.choice(len(predicted_probs), p=predicted_probs)\n",
    "#         # Convert the predicted word index back to the actual word\n",
    "#         predicted_word = tokenizer.index_word.get(predicted_word_index, \"\")\n",
    "#         # Update the seed text with the predicted word\n",
    "#         seed_text += \" \" + predicted_word\n",
    "#     return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aacd5719-dcf3-4375-a979-330e0503f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_word = \"Thank You !\"\n",
    "# input_text = \"Welcome\"\n",
    "# print(\"Welcome to the chatbot !\")\n",
    "# while input_text != stop_word :\n",
    "#     print(\"\\n\",generate_text(input_text, next_words=10, max_sequence_len=max_sequence_len))\n",
    "#     print(\"\\n\")\n",
    "#     input_text = input(\"Enter your response : \")\n",
    "\n",
    "# print(\"\\n\\n\\nIt was great talking with you !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf70fb84-8544-4b1e-b649-bb9d3c95cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(input_text, history=[]):\n",
    "    input_seq = tokenizer.texts_to_sequences([input_text])[0]\n",
    "    max_sequence_len = 100\n",
    "    input_seq = tf.keras.preprocessing.sequence.pad_sequences([input_seq], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(input_seq)\n",
    "    predicted_word_index = maths.argmax(predicted_probs)\n",
    "    predicted_word = tokenizer.index_word.get(predicted_word_index, \"\")\n",
    "    return predicted_word, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "304bcff2-85e9-48da-9c43-1756c6ec55d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language model loaded \n",
    "model = load_model('new_trained_model_treebank.keras')  \n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)  \n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb0127fc-d179-4b4d-a97a-1a8f75b1751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  yellow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Chatbot: in\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Chatbot: the\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Chatbot: the\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Chatbot: the\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  adf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Chatbot: the\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "print(\"Chatbot: Hello! How can I assist you today?\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    response, history = generate_response(user_input, history)\n",
    "    print(\"Chatbot:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
